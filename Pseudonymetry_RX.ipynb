{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bb419c",
   "metadata": {},
   "source": [
    "## Pseudonym Detection Under Non-Gaussian Interferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb307f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import datetime\n",
    "import scipy.signal as signal\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statistics as stats\n",
    "from scipy.spatial.distance import hamming\n",
    "import os\n",
    "\n",
    "rc('xtick', labelsize=14) \n",
    "rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "def readCom(file_path):\n",
    "    return np.fromfile(file_path, dtype=np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab62694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_string(timestamp):\n",
    "    '''\n",
    "    Helper function to get data and time from timestamp\n",
    "    INPUT: timestamp\n",
    "    OUTPUT: data and time. Example: 01-04-2023, 19:50:27\n",
    "    '''\n",
    "    date_time = datetime.datetime.fromtimestamp(int(timestamp))\n",
    "    return date_time.strftime(\"%m-%d-%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JsonLoad(folder, json_file):\n",
    "    '''\n",
    "    Load parameters from the saved json file\n",
    "    INPUT\n",
    "    ----\n",
    "        folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "        json_file: the json file with all the specifications. Example: '/save_iq_w_tx_gold.json'\n",
    "    OUTPUT\n",
    "    ----\n",
    "        samps_per_chip: samples per chip\n",
    "        wotxrepeat: number of repeating IQ sample collection w/o transmission. Used as an input to \n",
    "        traverse_dataset() func\n",
    "        rxrate: sampling rate at the receiver side\n",
    "    '''\n",
    "    #config_file = folder+'/'+json_file\n",
    "    #config_file = \"\"+\"/\"+str(folder)+\"/save_iq_w_tx_file.json\"\n",
    "    config_dict = json.load(open(json_file))[0]\n",
    "    nsamps = config_dict['nsamps']\n",
    "    rxrate = config_dict['rxrate']\n",
    "    rxfreq = config_dict['rxfreq']\n",
    "    wotxrepeat = config_dict['wotxrepeat']\n",
    "    rxrepeat = config_dict['rxrepeat']\n",
    "    txnodes = config_dict['txclients']\n",
    "    rxnodes = config_dict['rxclients']\n",
    "\n",
    "    return rxrepeat, rxrate, txnodes, rxnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_dataset(meas_folder):\n",
    "    '''\n",
    "    Load data from hdf5 format measurement file\n",
    "    INPUT\n",
    "    ----\n",
    "        meas_folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "    OUTPUT\n",
    "    ----\n",
    "        data: Collected IQ samples w/ transmission. It is indexed by the transmitter name\n",
    "        noise: Collected IQ samples w/o transmission. It is indexed by the transmitter name\n",
    "        txrxloc: transmitter and receiver names\n",
    "    '''\n",
    "    data = {}\n",
    "    noise = {}\n",
    "    txrxloc = {}\n",
    "\n",
    "    dataset = h5py.File(meas_folder + '/measurements.hdf5', \"r\") #meas_folder\n",
    "    #print(\"Dataset meta data:\", list(dataset.attrs.items()))\n",
    "    for cmd in dataset.keys():\n",
    "        #print(\"Command:\", cmd)\n",
    "        if cmd == 'saveiq':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "           # print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for rx_gain in dataset[cmd][cmd_time].keys():\n",
    "               # print(\"   RX gain:\", rx_gain)\n",
    "                for rx in dataset[cmd][cmd_time][rx_gain].keys():\n",
    "                    print(\"\")\n",
    "                    #print(\"     RX:\", rx)\n",
    "                    #print(\"       Measurement items:\", list(dataset[cmd][cmd_time][rx_gain][rx].keys()))\n",
    "        elif cmd == 'saveiq_w_tx':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "            #print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for tx in dataset[cmd][cmd_time].keys():\n",
    "                #print(\"   TX:\", tx)\n",
    "                \n",
    "                if tx == 'wo_tx':\n",
    "                    for rx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"       RX gain:\", rx_gain)\n",
    "                       # print(dataset[cmd][cmd_time][tx][rx_gain].keys())\n",
    "                        for rx in dataset[cmd][cmd_time][tx][rx_gain].keys():\n",
    "                            #print(\"         RX:\", rx)\n",
    "                            #print(\"           Measurement items:\", list(dataset[cmd][cmd_time][tx][rx_gain][rx].keys()))\n",
    "                            repeat = np.shape(dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'])[0]\n",
    "                            #print(\"         repeat\", repeat)\n",
    "\n",
    "                            samplesNotx =  dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                            namelist = rx.split('-')\n",
    "                            noise[namelist[1]] = samplesNotx\n",
    "                else:\n",
    "                    for tx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"     TX gain:\", tx_gain)\n",
    "                        for rx_gain in dataset[cmd][cmd_time][tx][tx_gain].keys():\n",
    "                            #print(\"       RX gain:\", rx_gain)\n",
    "                            #print(dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys())\n",
    "                            for rx in dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys():\n",
    "                                repeat = np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'])[0]\n",
    "                                #print(\"         RX:\", rx, \"; samples shape\", np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples']))\n",
    "                                #print(\"         Measurement items:\", list(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx].keys()))\n",
    "                                # print(\"         rxloc\", (dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxloc'][0]))\n",
    "                                # peak avg check\n",
    "                                \n",
    "                                txrxloc.setdefault(tx, []).extend([rx]*repeat)\n",
    "                                rxsamples = dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                                data.setdefault(tx, []).append(np.array(rxsamples))\n",
    "\n",
    "        else:                       \n",
    "            print('Unsupported command: ', cmd)\n",
    "\n",
    "    return data, noise, txrxloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: perform preamble synchronization\n",
    "#          Uses the (complex-valued) preamble signal. The cross-correlation \n",
    "#          of the preamble signal and the received signal (at the time\n",
    "#          when the preamble is received) should have highest magnitude\n",
    "#          at the index delay where the preamble approximately starts.  \n",
    "# INPUT:   rx0: received signal (with a frequency offset)\n",
    "#          preambleSignal: complex, known, transmitted preamble signal \n",
    "# OUTPUT:  lagIndex: the index of rx0 where the preamble signal has highest \n",
    "#              cross-correlation\n",
    "#\n",
    "def crossCorrelationMax(rx0, preambleSignal):\n",
    "\n",
    "    # Cross correlate with the preamble to find it in the noisy signal\n",
    "    lags      = signal.correlation_lags(len(rx0), len(preambleSignal), mode='valid')\n",
    "    xcorr_out = signal.correlate(rx0, preambleSignal, mode='valid')\n",
    "    xcorr_mag = np.abs(xcorr_out)\n",
    "    # Don't let it sync to the end of the packet.\n",
    "    packetLenSamples = 168000\n",
    "    maxIndex = np.argmax(xcorr_mag[:len(xcorr_mag)-packetLenSamples])\n",
    "    lagIndex = lags[maxIndex]\n",
    "\n",
    "    #print('Max crosscorrelation with preamble at lag ' + str(lagIndex))\n",
    "\n",
    "#     # Plot the selected signal.\n",
    "#     plt.figure()\n",
    "#     fig, subfigs = plt.subplots(2,1)\n",
    "#     subfigs[0].plot(np.real(rx0), label='Real RX Signal')\n",
    "#     subfigs[0].plot(np.imag(rx0), label='Imag RX Signal')\n",
    "#     scale_factor = np.mean(np.abs(rx0))/np.mean(np.abs(preambleSignal))\n",
    "#     subfigs[0].plot(range(lagIndex, lagIndex + len(preambleSignal)), scale_factor*np.real(preambleSignal), label='Preamble')\n",
    "#     subfigs[0].legend()\n",
    "#     subfigs[1].plot(lags, xcorr_mag, label='|X-Correlation|')\n",
    "#     plt.xlabel('Sample Index', fontsize=14)\n",
    "#     plt.tight_layout()\n",
    "\n",
    "    return lagIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc19c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2bits(message):\n",
    "    # Convert to characters of '1' and '0' in a vector.\n",
    "    temp_message = []\n",
    "    final_message = []\n",
    "    for each in message:\n",
    "        temp_message.append(format(ord(each), '07b'))\n",
    "    for every in temp_message:\n",
    "        for digit in every:\n",
    "            final_message.append(int(digit))\n",
    "    return final_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e2083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Calculate_mean(x):\n",
    "#     swap = np.zeros(49,)\n",
    "#     for i in range(49):\n",
    "#         swap[i] = sum(abs(x[i*N:(i+1)*N])**2)\n",
    "#         print('Received power:',swap[i])\n",
    "#     return np.median(swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binvector2str(binvector):\n",
    "    #binvector = binvector[0]\n",
    "    length = len(binvector)\n",
    "    eps = np.finfo('float').eps\n",
    "    if abs(length/7 - round(length/7)) > eps:\n",
    "        print('Length of bit stream must be a multiple of 7 to convert to a string.')\n",
    "    # Each character requires 7 bits in standard ASCII\n",
    "    num_characters = round(length/7)\n",
    "    # Maximum value is first in the vector. Otherwise would use 0:1:length-1\n",
    "    start = 6\n",
    "    bin_values = []\n",
    "    while start >= 0:\n",
    "        bin_values.append(int(math.pow(2,start)))\n",
    "        start = start - 1\n",
    "    bin_values = np.array(bin_values)\n",
    "    bin_values = np.transpose(bin_values)\n",
    "    str_out = '' # Initialize character vector\n",
    "    for i in range(num_characters):\n",
    "        single_char = binvector[i*7:i*7+7]\n",
    "        value = 0\n",
    "        for counter in range(len(single_char)):\n",
    "            value = value + (int(single_char[counter]) * int(bin_values[counter]))\n",
    "        str_out += chr(int(value))\n",
    "    return str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a11c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: create a modulated signal with the defined preamble\n",
    "# INPUT: A (sqrt value for modulation), N, alpha, Lp (for srrc)\n",
    "# OUTPUT: modulated preamble signal & srrc pulse\n",
    "def createPreambleSignal(A, N, alpha, Lp):\n",
    "\n",
    "    # We defined the preamble as this repeating bit signal:\n",
    "    preamble     = np.tile([1, 1, 0, 0], 16)\n",
    "\n",
    "    ###########################################\n",
    "    ### Signal Generation\n",
    "    ### INPUT: binary data\n",
    "    ### OUTPUT: 4-ary data (0..3) values\n",
    "    data = binary2mary(preamble, 4)\n",
    "\n",
    "    ###########################################\n",
    "    ### Modulation\n",
    "    ### INPUT: data\n",
    "    ### OUTPUT: modulated values, x\n",
    "    inputVec   = [0, 1, 2, 3]\n",
    "    outputVecI = [A, -A, A, -A]\n",
    "    outputVecQ = [A, A, -A, -A]\n",
    "    xI         = lut(data, inputVec, outputVecI)\n",
    "    xQ         = lut(data, inputVec, outputVecQ)\n",
    "    xI = xI.reshape((1,len(data)))\n",
    "    xQ = xQ.reshape((1,len(data)))\n",
    "    ###########################################\n",
    "    ### Upsample\n",
    "    ### INPUT: modulated values, x\n",
    "    ### OUTPUT: modulated values at sampling rate, x_s\n",
    "    x_s_I = oversample(xI, N)\n",
    "    x_s_Q = oversample(xQ, N)\n",
    "\n",
    "    ###########################################\n",
    "    ### Pulse-shape filter\n",
    "    ### INPUT: modulated values at sampling rate, x_s\n",
    "    ### OUTPUT: baseband transmit signal s\n",
    "\n",
    "    pulse = SRRC(alpha, N, Lp)\n",
    "    pulse = np.array(pulse)\n",
    "    pulse = np.reshape(pulse, pulse.size)\n",
    "    x_s_I = np.reshape(x_s_I, x_s_I.size)\n",
    "    x_s_Q = np.reshape(x_s_Q, x_s_Q.size)\n",
    "    s_0_I = np.convolve(x_s_I, pulse, mode='full')\n",
    "    s_0_Q = np.convolve(x_s_Q, pulse, mode='full')\n",
    "#     plt.figure()\n",
    "#     plt.plot(pulse,label='SRRC pulse shape')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    \n",
    "    preamb = s_0_I + 1j*s_0_Q\n",
    "    #preamb = np.insert(s,0,np.zeros(1024))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(np.real(preamb),label='Real Signal')\n",
    "#     plt.plot(np.imag(preamb),label='Imag Signal')\n",
    "#     plt.grid('on')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    return preamb, pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: Convert binary data to M-ary by making groups of log2(M)\n",
    "#          bits and converting each bit to one M-ary digit.\n",
    "# INPUT: Binary digit vector, with length as a multiple of log2(M)\n",
    "# OUTPUT: M-ary digit vector\n",
    "def binary2mary(data, M):\n",
    "\n",
    "    log2M   = round(np.log2(M))\n",
    "    # integer number of bits per group\n",
    "    if (len(data) % log2M) != 0:\n",
    "        print('Input to binary2mary must be divisible by log2(m).')\n",
    "    data.shape = (len(data)//log2M, log2M)\n",
    "    binaryValuesArray = 2**np.arange(log2M)\n",
    "    marydata = data.dot(binaryValuesArray)\n",
    "    return marydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1237df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: convert input data stream to signal space values for\n",
    "#          a particular modulation type (as specified by the inputVec\n",
    "#          and outputVec).\n",
    "# INPUT: data (groups of bits)\n",
    "# OUTPUT: signal space values\n",
    "def lut(data, inputVec, outputVec):\n",
    "    if len(inputVec) != len(outputVec):\n",
    "        print('Input and Output vectors must have identical length')\n",
    "    # Initialize output\n",
    "    output = np.zeros(data.shape)\n",
    "    # For each possible data value\n",
    "    eps = np.finfo('float').eps\n",
    "    for i in range(len(inputVec)):\n",
    "        # Find the indices where data is equal to that input value\n",
    "        for k in range(len(data)):\n",
    "            if abs(data[k]-inputVec[i]) < eps:\n",
    "                # Set those indices in the output to be the appropriate output value.\n",
    "                output[k] = outputVec[i]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46028945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: insert 0's between samples to oversample at OS_Rate\n",
    "# INPUT: x (data), OS_Rate (how frequently data occurs)\n",
    "# OUTPUT: x_s (oversampled data)\n",
    "def oversample(x, OS_Rate):\n",
    "    # Initialize output\n",
    "    length = len(x[0])\n",
    "    x_s = np.zeros((1,length*OS_Rate))\n",
    "    # Fill in one out of every OS_Rate samples with the input values\n",
    "    count = 0\n",
    "    h = 0\n",
    "    for k in range(len(x_s[0])):\n",
    "        count = count + 1\n",
    "        if count == OS_Rate:\n",
    "            x_s[0][k] = x[0][h]\n",
    "            count = 0\n",
    "            h = h + 1\n",
    "    return x_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: create a square root raised cosine pulse shape\n",
    "# INPUT: alpha, N, Lp\n",
    "# OUTPUT: pulse wave array for srrc\n",
    "def SRRC(alpha, N, Lp):\n",
    "    # Add epsilon to the n values to avoid numerical problems\n",
    "    n = np.arange(-N*Lp+ (1e-9), N*Lp+1)\n",
    "    h = np.zeros(len(n))\n",
    "    coeff = 1/np.sqrt(N)\n",
    "    for i, each in enumerate(n):\n",
    "        sine_term = np.sin(np.pi * each * (1-alpha) / N)\n",
    "        cosine_term = np.cos(np.pi * each * (1+alpha) / N)\n",
    "        cosine_coeff = 4 * alpha * each / N\n",
    "        numerator = sine_term + (cosine_coeff * cosine_term)\n",
    "        denom_coeff = np.pi * each / N\n",
    "        denom_part = 1 - cosine_coeff**2\n",
    "        denominator = denom_coeff * denom_part\n",
    "        h[i] = coeff * numerator / denominator\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make p-bit decisions by comparing patterns on bit-0 and bit-1\n",
    "## Trace changes in power with the p-bit and compare it with the known chip pattern.\n",
    "## This algorithm improves pseudonym detection in the presence of non-Gaussion type interferences\n",
    "\n",
    "def Matched_Filter_Pseudonym_Detection_Algorithm(x):\n",
    "    matching_filter =np.array([1,-1,1,-1,1,-1,1,-1,1,-1])\n",
    "    p_bit = []\n",
    "    for i in range(28):\n",
    "        pbit_data = x[i*packet:(i+1)*packet] # slices samples into one p-bit data = 6000 samples\n",
    "        \n",
    "        power = []\n",
    "        for j in range(10):\n",
    "            chip_data = pbit_data[j*samples:(j+1)*samples] # slice p-bit data into chip data = 600 samples\n",
    "            power.append(sum(abs(chip_data)**2))\n",
    "       \n",
    "        #plt.plot(power)\n",
    "        #plt.show()\n",
    "        \n",
    "        threshold = 0.0\n",
    "        quantization_level = np.array([1,-1])\n",
    "        for k in range(9):\n",
    "            if power[k] > power[k+1]:\n",
    "                power[k] = quantization_level[0]\n",
    "            else:\n",
    "                power[k] = quantization_level[1]\n",
    "        if power[8] < power[9]:\n",
    "            power[9] = quantization_level[0]\n",
    "        else:\n",
    "            power[9] = quantization_level[1]\n",
    "            \n",
    "        pseudonym_power = np.dot(power,matching_filter)#compute the pseudonym power by taking the inner product       \n",
    "\n",
    "        if pseudonym_power > threshold: # p-bit decision done by comparing p-bit powers with the threshold.\n",
    "            p_bit.append(1)\n",
    "        else:\n",
    "            p_bit.append(0)  \n",
    "    return np.array(p_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcb671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculates the distance between the recoded pseudonym bits and the transmitted(true) pseudonym bits.\n",
    "'''\n",
    "def Distance(X,Y):\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if X[i]!= Y[i]:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a1579",
   "metadata": {},
   "source": [
    "### RX Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b791e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.sqrt(9/2)\n",
    "N = 8\n",
    "alpha = 0.5\n",
    "Lp = 6\n",
    "preambleSignal, pulse = createPreambleSignal(A, N, alpha, Lp)\n",
    "count_swap = 0\n",
    "#print(\"Preamble signal:\",preambleSignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40cb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Protocol parameters!!!\n",
    "'''\n",
    "packet = 6000\n",
    "samples = 600\n",
    "pseudonym_len = 28\n",
    "mess_length = packet*pseudonym_len\n",
    "repeat = 10\n",
    "message = 'STOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837635d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Folders(x):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(x):\n",
    "        r.append(dirs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "def Calculate_Eb_No(x):\n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    " \n",
    "    #folder = x\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "    samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp' # select the TX\n",
    "    rxloc = 'cbrssdr1-browning-comp' # select the RX\n",
    "    \n",
    "    #Calculate SNR\n",
    "    Noise = rx_noise['browning'][0]  # measure the RX power while the TX is turned off\n",
    "    noise_power = sum(abs(Noise)**2)/len(Noise)\n",
    "    \n",
    "    # initialize error\n",
    "    \n",
    "    P_s = 0\n",
    "\n",
    "    for i in range(repeat):    \n",
    "        repNum = i\n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][repNum]\n",
    "        \n",
    "        # synchronize pseudonym using preamble signal\n",
    "        lagIndex = crossCorrelationMax(rx0, preambleSignal)\n",
    "        start_of_data = lagIndex + len(preambleSignal)\n",
    "        Rx_signal = rx0[start_of_data:mess_length+start_of_data]\n",
    "\n",
    "       \n",
    "        P_s += sum(abs(Rx_signal)**2)/len(Rx_signal)\n",
    "\n",
    "    signal_power = P_s/repeat   \n",
    "    return signal_power, noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e49884",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "\n",
    "def Calculate_Pseudonym_BER(x):\n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    " \n",
    "    #folder = x\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "    samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'\n",
    "    rxloc = 'cbrssdr1-browning-comp'\n",
    "\n",
    "    # initialize error\n",
    "    pseudonym_BER = 0\n",
    "    P_s = 0\n",
    "    count = 0\n",
    "    for i in range(repeat):    \n",
    "        repNum = i\n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][repNum]\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # synchronize pseudonym using preamble signal\n",
    "        lagIndex = crossCorrelationMax(rx0, preambleSignal)\n",
    "        start_of_data = lagIndex + len(preambleSignal)\n",
    "        Rx_signal = rx0[start_of_data:mess_length+start_of_data]\n",
    "\n",
    "        estimate_pseudonym = Matched_Filter_Pseudonym_Detection_Algorithm(Rx_signal)\n",
    "        \n",
    "        if binvector2str(estimate_pseudonym) == 'STOP':\n",
    "            print('Detected Packet:',binvector2str(estimate_pseudonym))\n",
    "            print('Pseudonym is correctly detected in ', 85*count, 'ms \\n')\n",
    "            break\n",
    "        else:\n",
    "            print('Detected packet:',binvector2str(estimate_pseudonym), '\\n')\n",
    "    \n",
    "        pseudonym_BER += Distance(text2bits('STOP'),estimate_pseudonym)\n",
    "            # calculate the average signal power in each repeat\n",
    "            # signal power = total power - estimated noise power\n",
    "    return pseudonym_BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load collected IQ samples from file\n",
    "def readCom(file_path):\n",
    "    return np.fromfile(file_path, dtype=np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f28914",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the average pseudonym error in the experiment.\n",
    "Experiment data is stored in folders that contain 10 repeats each.\n",
    "'''\n",
    "def Pseudonym_Detection_Algorithm(x):\n",
    "    folders = Extract_Folders(x)[0]\n",
    "    num_folder = len(folders)\n",
    "    pseudonym_BER = 0\n",
    "    signal = 0\n",
    "    noise = 0\n",
    "    for i in range(len(folders)):\n",
    "        s,n = Calculate_Eb_No(folders[i])\n",
    "        signal += s\n",
    "        noise += n\n",
    "    Eb_No = 10*(np.log10(0.5*(signal-noise)/noise))\n",
    "    \n",
    "    print('Our Pseudonym message is:', 'STOP')\n",
    "\n",
    "    print('The Eb/N0 at the RX:',Eb_No)\n",
    "    print('Data rate: 2Mbps')\n",
    "    print('Considering only pseudonym transmission latency: \\n')\n",
    "    for i in range(len(folders)):\n",
    "        print('Experiment No.:',i+1, '\\n')\n",
    "     \n",
    "        BER = Calculate_Pseudonym_BER(folders[i])\n",
    "        pseudonym_BER += BER\n",
    "    \n",
    "    p_bit_error = pseudonym_BER/(num_folder*repeat*pseudonym_len)\n",
    "    return p_bit_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730424fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PURPOSE: Detection power change patterns at the received IQ samples and estimates the pseudonym packet.\n",
    "\n",
    "Pseudonym_Detection_Algorithm(\"-15dB_data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
